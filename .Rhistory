adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training_sub<-subset(training, select=grep("^IL", names(training)))
preProc<-preProcess(training_sub, method="pca", thresh=0.80)
train_PCA<-predict(preProc, training_sub)
training_sub<-cbind(training_sub, training$diagnosis)
train_PCA<-cbind(train_PCA, training$diagnosis)
names(training_sub)[ncol(training_sub)]<-"diagnosis"
names(train_PCA)[ncol(train_PCA)]<-"diagnosis"
modelRaw<-train(diagnosis~., method="glm", data=training_sub)
modelPCA<-train(diagnosis~., method="glm", data=train_PCA)
str(testing)
testPCA<-predict(preProc, testing[,-1])
testing[-1]
str(testing[-1])
testPCA<-predict(preProc, testing[,-1])
head(names(tesging))
head(names(testing))
testing_sub<-subset(testing, select=grep("ÎL", names(tesging)))
testing_sub<-subset(testing, select=grep("^IL", names(tesging)))
testing_sub<-subset(testing, select=grep("^IL", names(testing)))
str(tesging_sub)
str(testing_sub)
testPCA<-predict(preProc, testing_sub)
confusionMatrix(testing$diagnosis, predict(modelPCA, testPCA))
data(iris); library(ggplot2)
names(iris)
qplot(Petal.Width, Sepal.Width, colour=Species, data=training)
inTrain<-createDataPartition(y=iris$Species, p=0.7, list=FALSE)
library(caret)
inTrain<-createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
qplot(Petal.Width, Sepal.Width, colour=Species, data=training)
modFit<-train(Species~., method="rpart", data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=T, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata=testing)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(ozone, package="ElemStatLearn")
head(ozone)
ozone<-ozone[order(ozone$ozone),]
head(ozone)
ll<-matrix(NA, nrow=10, ncol=155)
for (i in 1:10){
ss<-sample(1:dim(ozone)[1], replace=T)
ozone0<-ozone[ss,]; ozone0<-ozone0[order(ozone0$ozone),]
loess0<-loess(temperature~ozone, data=ozone0, span=0.2)
ll[i,]<-predict(loess0, newdata=data.frame(ozone=1:155))
}
ll
plot(ozone$ozone, ozone$temperature, pch=19, cex=0.5)
for(i in 1:10){lines(1:155, ll[i,], col="grey", lwd=2)}
lines(1:155, apply(ll, 2, mean), col="red", lwd=2)
data(iris); librry(gglot2)
inTrain<-createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
library(caret)
data(iris); library(gglot2)
inTrain<-createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training<-iris[inTrain,]
testing<-iris[-inTrain,]
modFit<-train(Specias~., data=training, method="rf", prox=TRUE)
modFit<-train(Species~., data=training, method="rf", prox=TRUE)
modFit
getTree(modFit$finalModel, k=2)
irisP<-classCenter(training[,c(3,4)], train$Species, modelFit$finalModel$prox)
irisP<-classCenter(training[,c(3,4)], training$Species, modelFit$finalModel$prox)
irisP<-classCenter(training[,c(3,4)], training$Species, modeFit$finalModel$prox)
irisP<-classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP
modFit$finalModel$prox
dim(iris)
dim(modFit$finalModel$prox)
irisP<-as.data.frame(irisP); irisP$Species<-rownames(irisP)
p<-qplot(Petal.Width, Petal.Length, col=Species, data=training)
plot(p)
irisP
p + geom_point(aes(x=Petal.Width, y=Petal.Length, col=Species), size=5, shape=4, data=irisP)
pred<-predict(modFit, testing); testing$PredRight<-pred==testing$Species ## añadimos columna de predicciones correctas
## confusion matrix
table(pred, testing$Species)
qplot(Petal.Width, Petal.Length, colour=PredRigth, data=testing, main="newdata Predictions")
qplot(Petal.Width, Petal.Length, colour=PredRight, data=testing, main="newdata Predictions")
a<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
dim(a)
names(a)
head(a$X)
length(unique(a$X))
dim(a)
sum(is.na(a))
apply(a, 2 function(x) sum(is.na(x)))
apply(a, 2, function(x) sum(is.na(x)))
head()
head(a)
class(a$user_name)
levels(a$user_name)
names(a)
apply(a, 2, class)
apply(a, 2, function(x) sum(is.na(a)))
data<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
library(caret)
## partitioning the data set
inTrain<-createDataPartition(y=data$classe, p=0.7, list=FALSE)
?TRAIN
?trarin
?train
?trControl
?trainControl
pr<-data
train(classe~. data=pr, trainControl(method="cv"), method="rpart")
train(classe~., data=pr, trainControl(method="cv"), method="rpart")
train(classe~., data=pr, trControl=trainControl("cv"), method="rpart")
there are a large number of blank spaces that should be interpreted as NAs
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
test<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
na.strings=c(NA, ""))
names(training)
prenames<-names(training)
nonNAcolumns<-names(training)[apply(training, 2, function(x) sum(is.na(x)))<19216]
training<-training[,nonNAcolumns]
## the same for the testing set. We have to drop "classe" from nonNAcolumns vector first
testing<-test[,nonNAcolumns[-length(nonNAcolumns)]]
## Dropping the first column, X, since it is an identifier of an observation
training<-training[,-1]
testing<-testing[,-1]
## hour/date column
## this column shows the time when the activity was perfomed for each individual. The only
## reason this column is not perfectly correlated with user_name is because a minute switch
## ocurred during the recording of the session. the timestamp variables also correspond to
## time. we can also drop these variables
with(training, table(user_name, cvtd_timestamp))
## we opt for dropping this column
training<-training[,-c(2:4)]
testing<-testing[-c(2:4)]
## Extreme values
figure_extreme<-"C:/Users/martin/Desktop/Data Science/Practical Machine learning/project/figures/extreme"
for (idx in 3:ncol(training)-1){
png(paste(figure_extreme, "/", idx, ".png", sep=""))
plot(training[,idx], col=training$classe)
dev.off()
}
## Extreme in variable: 34, 35, 36, 41, 46, 47, 48, 49
extreme.obs<-c(which.min(training[,34]),
which.max(training[,35]),
which.max(training[,36]),
which.max(training[,37]),
which.min(training[,41]),
which.max(training[,46]),
which.min(training[,47]),
which.max(training[,48]),
which.max(training[,49]))
extreme.obs
## are in three different observations: 5373, 9029 and 9274
training<-training[-unique(extreme.obs),]
names(training)
prenames
names(training)
preProc<-preProcess(training[-ncol(training)], method="pca")
library(caret)
preProc<-preProcess(training[-ncol(training)], method="pca")
summary(training$new_window)
names(training)
summary(training$num_window)
dum<-dummyVars(new_window, data=training)
names(training)
?dummyVars
dum<-dummyVars(classe~new_window, data=training)
head(predict(dum))
head(predict(dum, training))
names(training)
preProc<-preProcess(training[-c(2,56)], method="pca")
preProc<-preProcess(as.numeric(training[-c(2,56)]), method="pca")
sapply(training, class)
training[,-c(training$user_name)]
training<-training[,-c(training$user_name)]
testing<-testing[,-c(testng$user_name)]
testing<-testing[,-c(testing$user_name)]
names(training)
library(caret)
## there are a large number of blank spaces that should be interpreted as NAs
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
test<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
na.strings=c(NA, ""))
prenames<-names(training)
## partitioning the data set
## K-FOLDS CROSS-VALIDATION. EL TEST SET SERÁ EL DEL SUBMIT DE COURSERA
## EXPLORATORY ANALYSIS
## Missing values
sum(is.na(data))
## columns with missing values
apply(training, 2, function(x){sum(is.na(x))})
## there are several columns all with a number of NAs equal to 19216, that is about only
## 2% of the number of observations.
nonNAcolumns<-names(training)[apply(training, 2, function(x) sum(is.na(x)))<19216]
training<-training[,nonNAcolumns]
## the same for the testing set. We have to drop "classe" from nonNAcolumns vector first
testing<-test[,nonNAcolumns[-length(nonNAcolumns)]]
## Dropping the first column, X, since it is an identifier of an observation
training<-training[,-1]
testing<-testing[,-1]
## hour/date column
## this column shows the time when the activity was perfomed for each individual. The only
## reason this column is not perfectly correlated with user_name is because a minute switch
## ocurred during the recording of the session. the timestamp variables also correspond to
## time. we can also drop these variables
with(training, table(user_name, cvtd_timestamp))
## we opt for dropping this column
training<-training[,-c(2:4)]
testing<-testing[-c(2:4)]
extreme.obs<-c(which.min(training[,34]),
which.max(training[,35]),
which.max(training[,36]),
which.max(training[,37]),
which.min(training[,41]),
which.max(training[,46]),
which.min(training[,47]),
which.max(training[,48]),
which.max(training[,49]))
training<-training[-unique(extreme.obs),]
training<-training[,-c(training$user_name)]
testing<-testing[,-c(testing$user_name)]
names(training)
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
test<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
na.strings=c(NA, ""))
names(training)
training<-training[,-c(training$X)]
testing<-testing[,-c(testing$X)]
names(testing)
names(training)
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
test<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
na.strings=c(NA, ""))
names(testing)
testing<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
na.strings=c(NA, ""))
nonNAcolumns<-names(training)[apply(training, 2, function(x) sum(is.na(x)))<19216]
training<-training[,nonNAcolumns]
## the same for the testing set. We have to drop "classe" from nonNAcolumns vector first
testing<-testing[,nonNAcolumns[-length(nonNAcolumns)]]
training<-training[,-c(training$X)]
testing<-testing[,-c(testing$X)]
names(training)
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
testing<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
na.strings=c(NA, ""))
names(training)
nonNAcolumns<-names(training)[apply(training, 2, function(x) sum(is.na(x)))<19216]
training<-training[,nonNAcolumns]
names(training)
testing<-testing[,nonNAcolumns[-length(nonNAcolumns)]]
training<-training[,-c(training$X)]
names(training)
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
testing<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
na.strings=c(NA, ""))
prenames<-names(training)
## partitioning the data set
## K-FOLDS CROSS-VALIDATION. EL TEST SET SERÁ EL DEL SUBMIT DE COURSERA
## EXPLORATORY ANALYSIS
## Missing values
sum(is.na(data))
## columns with missing values
apply(training, 2, function(x){sum(is.na(x))})
## there are several columns all with a number of NAs equal to 19216, that is about only
## 2% of the number of observations.
nonNAcolumns<-names(training)[apply(training, 2, function(x) sum(is.na(x)))<19216]
training<-training[,nonNAcolumns]
## the same for the testing set. We have to drop "classe" from nonNAcolumns vector first
testing<-testing[,nonNAcolumns[-length(nonNAcolumns)]]
library(caret)
## there are a large number of blank spaces that should be interpreted as NAs
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
testing<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
na.strings=c(NA, ""))
nonNAcolumns<-names(training)[apply(training, 2, function(x) sum(is.na(x)))<19216]
training<-training[,nonNAcolumns]
## the same for the testing set. We have to drop "classe" from nonNAcolumns vector first
testing<-testing[,nonNAcolumns[-length(nonNAcolumns)]]
training<-training[,-1]
testing<-testing[,-1]
training<-training[,-c(2:4)]
testing<-testing[-c(2:4)]
extreme.obs<-c(which.min(training[,34]),
which.max(training[,35]),
which.max(training[,36]),
which.max(training[,37]),
which.min(training[,41]),
which.max(training[,46]),
which.min(training[,47]),
which.max(training[,48]),
which.max(training[,49]))
training<-training[-unique(extreme.obs),]
library(randomForest)
training2<-training[,c(4,7,9, ncol(training))]
testing2<-testing[,c(4,7,9)]
modFit6<-randomForest(classe~., data=training2)
modFit6
training2<-training[,c(4,7,9,10,13,15,20,35,37,38,44, ncol(training))]
testing2<-testing[,c(4,7,9,10,13,15,20,35,37,38,44)]
modFit6<-randomForest(classe~., data=training2)
modFit6
cv.randomForest
cv.tree
library(tree)
cv.tree
cv.rf
predict(modFit6, testing2)
?cv.rf
?rfcv
training3<-training[,c(4,7,9,10,13,15,20,35,37,38,44)]
classe<-training$classe
rfcv(classe, training3, cv.fold=10)
rfcv(classe, training3, cv.fold=10, scale="")
rfcv(classe, training3, cv.fold=10, scale="normal")
rfcv(classe, training3, cv.fold=10)
rfcv(classe, training3, cv.fold=5)
rfcv(training3, classe cv.fold=5)
rfcv(training3, classe, cv.fold=5)
cv<-rfcv(training3, classe, cv.fold=5, step=1)
cv<-rfcv(training3, classe, cv.fold=5, step=0)
library(knitr)
dim(training)
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
dim(training)
names(training)
?read.cvsv
?read.csv
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", nrows=20)
head(training[,grep["total"]])
head(training[,grep("total", training)]
training[,grep("total", training)]
names(training)
training[,grep("total", names(training))]
head(training[,grep("total", names(training))],10)
```{r reading the file, cache=TRUE}
opts_chunk$set(cache=TRUE, warning=FALSE)
```
opts_chunk$set(cache=TRUE, warning=FALSE)
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", nrows=20)
training<-read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", nrows=20)
names(training)
head(training[,grep("avg", names(training))],10)
names(training)
head(training[,grep("avg|kurtosis", names(training))],10)
names(training)
head(training[,grep("total", names(training))],10)
head(training[,grep("avg", names(training))],10)
apply(training, 2, function(x){sum(is.na(x))})
training<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
apply(training, 2, function(x){sum(is.na(x))})
apply(training, 2, function(x){sum(is.na(x))})[sample(1:10)]
apply(training, 2, function(x){sum(is.na(x))})[sample(1:30)]
apply(training, 2, function(x){sum(is.na(x))})[sample(1:20)]
with(training, table(user_name, cvtd_timestamp))
nam
names(training)
## Predicting correct execution of weight lifting exercises
```{r reading the file, cache=TRUE, echo=FALSE}
library(knitr)
opts_chunk$set(cache=TRUE, warning=FALSE)
```
### Summary
Having an application displaying if an specific exercise is executed correctly can be very useful for sports practitioners. Using data from [Groupware@LES](http://groupware.les.inf.puc-rio.br/), which recorded the execution of weight lifting from six participant perfoming the activity in different ways.
A random forest was used with 5-fold cross-validation. A XX mean level of accuracy was achieved.
### The data. Exploratory analysis
```{r, echo=FALSE, cache=TRUE}
library(caret)
library(ggplot2)
```
The data is composed of 19622 observations and 160 features. The most part of them are meassurements from a gyroscope and an accelerometer. The features corresponding to a aggregation of this meassurements are mostly NAs or blank spaces. There are five different ways of performing an exercise (one of them is correct) labeled in the variable "classe" as A, B, C, D, E.
```{r, cache=TRUE}
training<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", nrows=20)
head(training[,grep("avg", names(training))],10)
```
So, the data is readed specifying blank spaces as NAs.
```{r, cache=TRUE}
training<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
na.strings=c(NA, ""))
getwd()
setwd(C:\Users\martin\Desktop\Data Science\Practical Machine learning\project)
setwd("C:/Users/martin/Desktop/Data Science/Practical Machine learning/project")
setwd("C:/Users/martin/Desktop/Data Science/Practical Machine learning/project")
19000*0.3
modFIt<-randomForest(classe~., data=training)
sum(is.na(training))
nrow
413*10
4125/10
training<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", nrows=20)
training<-read.csv("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings=c(NA, ""))
nonNAcolumns<-names(training)[apply(training, 2, function(x) sum(is.na(x)))<19216]
training<-training[,nonNAcolumns]
training<-training[,-c(1,3:5)]
set.seed(121)
inTrain<-createDataPartition(y=training$classe, p=0.7, list=FALSE)
training<-training[inTrain,]
cv<-training[-inTrain,]
modFit<-randomForest(classe~., data=training)
folds<-createFolds(y=cv$classe, k=5, returnTrain=FALSE)
folds[[1]]
cv1<-folds[[1]]
cv1<-cv[folds[[1]],]
cv1<-cv[folds[[1]],-c("classe")]
names(cv1)
classe.cv1<-folds[[1]]$classe
classe.cv1<-folds[[1]][,56]
classe.cv1<-cv[folds[[1]]$classe]
classe.cv1<-cv[folds[[1]],"classe"]
cv1<-cv[folds[[1]],-c56]
cv1<-cv[folds[[1]],-56]
predict(modFit, cv1)
pr1<-predict(modFit, cv1)
table(pr1, cv1)
table(pr1, classe.cv1)
classe.cv1<-cv[folds[[2]],"classe"]
cv1<-cv[folds[[2]],-56]
pr1<-predict(modFit, cv1)
table(pr1, classe.cv1)
classe.cv1<-cv[folds[[3]],"classe"]
cv1<-cv[folds[[3]],-56]
pr1<-predict(modFit, cv1)
table(pr1, classe.cv1)
classe.cv1<-cv[folds[[4]],"classe"]
cv1<-cv[folds[[4]],-56]
pr1<-predict(modFit, cv1)
table(pr1, classe.cv1)
classe.cv1<-cv[folds[[4]],"classe"]
cv1<-cv[folds[[5]],-56]
pr1<-predict(modFit, cv1)
table(pr1, classe.cv1)
classe.cv1<-cv[folds[[5]],"classe"]
cv1<-cv[folds[[5]],-56]
pr1<-predict(modFit, cv1)
table(pr1, classe.cv1)
pr1
cbind(pr1, cv1)
cbind(pr1, cñasse.cv1)
cbind(pr1, classe.cv1)
table(pr1, classe.cv1)
matr<-list(rep(NA, 5))
matr
mat[[1]]
matr[[1]]
matr[[2]]
matr<-list(vector(rep(NA, 5))
)
folds<-createFolds(y=cv$classe, k=5, returnTrain=FALSE)
predict(modFit, cv[folds[[1]], -c("classe")])
names(pr1)
names(pr1)
pred<-predict(modFit, cv1)
table(pred, classe.cv1)
pred
names(modFit)
with(modFit, sum(confusion)/sum(diag(confusion)))
sum(diag$modFit)
sum(diag(modFit$confusion))
with(modFit, sum(diag(confusion))/sum(confusion))
1-with(modFit, sum(diag(confusion))/sum(confusion))
matr<-list(rep(matrix())
)
matr
vector("list", 5)
matr<-list(vector("list",5))
matr<-list(vector("list",5))
for (idx in 1:5){
classe.cv<-cv[folds[[idx]],"classe"]
cv<-cv[folds[[idx]],-56]
pred<-predict(modFit, cv1)
conf<-table(pred, classe.cv1)
matr[[idx]]<-conf}
matr
with(modFit,sum(confusion)/sum(diag(confusion)))
1-with(modFit,sum(confusion)/sum(diag(confusion)))
with(modFit,sum(diag(confusion))/sum(confusion))
1-with(modFit,sum(diag(confusion))/sum(confusion))
folds<-createFolds(y=cv$classe, k=5, returnTrain=FALSE)
folds<-createFolds(y=cv$classe, k=10, returnTrain=FALSE)
folds<-createFolds(y=cv$classe, k=5, returnTrain=FALSE)
cv$classe
names(cv)
classe<-cbind(classe, classe.cv)
names(clase)
names(classe)
head(classe)
dim(classe)
cv<-cbind(cv, classe)
cv<-training[-inTrain,]
folds<-createFolds(y=cv$classe, k=5, returnTrain=FALSE)
folds<-createFolds(y=cv$classe, k=5, returnTrain=FALSE)
folds<-createFolds(y=cv$classe, k=5, returnTrain=FALSE)
